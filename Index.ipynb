{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spark liriaries\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.context import SQLContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import regexp_extract\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import sum as spark_sum\n",
    "from pyspark.sql.functions import desc, row_number, monotonically_increasing_id\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# load up other dependencies\n",
    "import re\n",
    "import glob\n",
    "#import optparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure spark variables\n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-16 12:55:36--  ftp://ita.ee.lbl.gov/traces/NASA_access_log_Aug95.gz\n",
      "           => ‘NASA_access_log_Aug95.gz.1’\n",
      "Resolving ita.ee.lbl.gov (ita.ee.lbl.gov)... 131.243.2.164, 2620:83:8000:102::a4\n",
      "Connecting to ita.ee.lbl.gov (ita.ee.lbl.gov)|131.243.2.164|:21... connected.\n",
      "Logging in as anonymous ... Logged in!\n",
      "==> SYST ... done.    ==> PWD ... done.\n",
      "==> TYPE I ... done.  ==> CWD (1) /traces ... done.\n",
      "==> SIZE NASA_access_log_Aug95.gz ... 16633316\n",
      "==> PASV ... done.    ==> RETR NASA_access_log_Aug95.gz ... done.\n",
      "Length: 16633316 (16M) (unauthoritative)\n",
      "\n",
      "NASA_access_log_Aug 100%[===================>]  15,86M  3,10MB/s    in 6,7s    \n",
      "\n",
      "2021-10-16 12:55:46 (2,35 MB/s) - ‘NASA_access_log_Aug95.gz.1’ saved [16633316]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download NASA_access_log_Aug95.gz file\n",
    "get_ipython().system(' wget ftp://ita.ee.lbl.gov/traces/NASA_access_log_Aug95.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NASA_access_log_Aug95.gz']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert data\n",
    "raw_data_files = glob.glob('*.gz')\n",
    "raw_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#produces a DataFrame with a single string column called value:\n",
    "base_df = spark.read.text(raw_data_files)\n",
    "base_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert a DataFrame into a Resilient Distributed Dataset (RDD)—Spark’s original data structure\n",
    "base_df_rdd = base_df.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1569898, 1)\n"
     ]
    }
   ],
   "source": [
    "#the total number of logs of the dataset\n",
    "print((base_df.count(), len(base_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in24.inetnebr.com - - [01/Aug/1995:00:00:01 -0400] \"GET /shuttle/missions/sts-68/news/sts-68-mcc-05.txt HTTP/1.0\" 200 1839',\n",
       " 'uplherc.upl.com - - [01/Aug/1995:00:00:07 -0400] \"GET / HTTP/1.0\" 304 0',\n",
       " 'uplherc.upl.com - - [01/Aug/1995:00:00:08 -0400] \"GET /images/ksclogo-medium.gif HTTP/1.0\" 304 0',\n",
       " 'uplherc.upl.com - - [01/Aug/1995:00:00:08 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 304 0',\n",
       " 'uplherc.upl.com - - [01/Aug/1995:00:00:08 -0400] \"GET /images/USA-logosmall.gif HTTP/1.0\" 304 0',\n",
       " 'ix-esc-ca2-07.ix.netcom.com - - [01/Aug/1995:00:00:09 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1713',\n",
       " 'uplherc.upl.com - - [01/Aug/1995:00:00:10 -0400] \"GET /images/WORLD-logosmall.gif HTTP/1.0\" 304 0',\n",
       " 'slppp6.intermind.net - - [01/Aug/1995:00:00:10 -0400] \"GET /history/skylab/skylab.html HTTP/1.0\" 200 1687',\n",
       " 'piweba4y.prodigy.com - - [01/Aug/1995:00:00:10 -0400] \"GET /images/launchmedium.gif HTTP/1.0\" 200 11853',\n",
       " 'slppp6.intermind.net - - [01/Aug/1995:00:00:11 -0400] \"GET /history/skylab/skylab-small.gif HTTP/1.0\" 200 9202',\n",
       " 'slppp6.intermind.net - - [01/Aug/1995:00:00:12 -0400] \"GET /images/ksclogosmall.gif HTTP/1.0\" 200 3635',\n",
       " 'ix-esc-ca2-07.ix.netcom.com - - [01/Aug/1995:00:00:12 -0400] \"GET /history/apollo/images/apollo-logo1.gif HTTP/1.0\" 200 1173',\n",
       " 'slppp6.intermind.net - - [01/Aug/1995:00:00:13 -0400] \"GET /history/apollo/images/apollo-logo.gif HTTP/1.0\" 200 3047',\n",
       " 'uplherc.upl.com - - [01/Aug/1995:00:00:14 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0',\n",
       " '133.43.96.45 - - [01/Aug/1995:00:00:16 -0400] \"GET /shuttle/missions/sts-69/mission-sts-69.html HTTP/1.0\" 200 10566']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract and have a look of some sample log messages\n",
    "sample_logs = [item['value'] for item in base_df.take(15)]\n",
    "sample_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting hostnames - with regular expressions extract the hostname from the logs\n",
    "host_pattern = r'(^\\S+\\.[\\S+\\.]+\\S+)\\s'\n",
    "hosts = [re.search(host_pattern, item).group(1)\n",
    "           if re.search(host_pattern, item)\n",
    "           else 'no match'\n",
    "           for item in sample_logs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting timestamps - with regular expressions extract the timestamp fields from the logs\n",
    "ts_pattern = r'\\[(\\d{2}/\\w{3}/\\d{4}:\\d{2}:\\d{2}:\\d{2} -\\d{4})]'\n",
    "timestamps = [re.search(ts_pattern, item).group(1) for item in sample_logs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting HTTP request method, URIs, and protocol - \n",
    "# with regular expressions extract the HTTP request methods, URIs, and Protocol patterns fields from the logs\n",
    "method_uri_protocol_pattern = r'\\\"(\\S+)\\s(\\S+)\\s*(\\S*)\\\"'\n",
    "method_uri_protocol = [re.search(method_uri_protocol_pattern, item).groups()\n",
    "               if re.search(method_uri_protocol_pattern, item)\n",
    "               else 'no match'\n",
    "              for item in sample_logs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting HTTP status codes - with regular expressions extract the HTTP status codes from the logs\n",
    "status_pattern = r'\\s(\\d{3})\\s'\n",
    "status = [re.search(status_pattern, item).group(1) for item in sample_logs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting HTTP response content size - \n",
    "# with regular expressions extract the HTTP response content size from the logs\n",
    "content_size_pattern = r'\\s(\\d+)$'\n",
    "content_size = [re.search(content_size_pattern, item).group(1) for item in sample_logs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+--------------------+--------+------+------------+\n",
      "|                host|           timestamp|method|            endpoint|protocol|status|content_size|\n",
      "+--------------------+--------------------+------+--------------------+--------+------+------------+\n",
      "|   in24.inetnebr.com|01/Aug/1995:00:00...|   GET|/shuttle/missions...|HTTP/1.0|   200|        1839|\n",
      "|     uplherc.upl.com|01/Aug/1995:00:00...|   GET|                   /|HTTP/1.0|   304|           0|\n",
      "|     uplherc.upl.com|01/Aug/1995:00:00...|   GET|/images/ksclogo-m...|HTTP/1.0|   304|           0|\n",
      "|     uplherc.upl.com|01/Aug/1995:00:00...|   GET|/images/MOSAIC-lo...|HTTP/1.0|   304|           0|\n",
      "|     uplherc.upl.com|01/Aug/1995:00:00...|   GET|/images/USA-logos...|HTTP/1.0|   304|           0|\n",
      "|ix-esc-ca2-07.ix....|01/Aug/1995:00:00...|   GET|/images/launch-lo...|HTTP/1.0|   200|        1713|\n",
      "|     uplherc.upl.com|01/Aug/1995:00:00...|   GET|/images/WORLD-log...|HTTP/1.0|   304|           0|\n",
      "|slppp6.intermind.net|01/Aug/1995:00:00...|   GET|/history/skylab/s...|HTTP/1.0|   200|        1687|\n",
      "|piweba4y.prodigy.com|01/Aug/1995:00:00...|   GET|/images/launchmed...|HTTP/1.0|   200|       11853|\n",
      "|slppp6.intermind.net|01/Aug/1995:00:00...|   GET|/history/skylab/s...|HTTP/1.0|   200|        9202|\n",
      "+--------------------+--------------------+------+--------------------+--------+------+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "(1569898, 7)\n"
     ]
    }
   ],
   "source": [
    "# Putting it all together - \n",
    "# We build our DataFrame with all of the log attributes neatly extracted in their own separate columns\n",
    "logs_df = base_df.select(regexp_extract('value', host_pattern, 1).alias('host'),\n",
    "                         regexp_extract('value', ts_pattern, 1).alias('timestamp'),\n",
    "                         regexp_extract('value', method_uri_protocol_pattern, 1).alias('method'),\n",
    "                         regexp_extract('value', method_uri_protocol_pattern, 2).alias('endpoint'),\n",
    "                         regexp_extract('value', method_uri_protocol_pattern, 3).alias('protocol'),\n",
    "                         regexp_extract('value', status_pattern, 1).cast('integer').alias('status'),\n",
    "                         regexp_extract('value', content_size_pattern, 1).cast('integer').alias('content_size'))\n",
    "logs_df.show(10, truncate=True)\n",
    "print((logs_df.count(), len(logs_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+--------------------+--------+------+------------+-----+\n",
      "|                host|           timestamp|method|            endpoint|protocol|status|content_size|index|\n",
      "+--------------------+--------------------+------+--------------------+--------+------+------------+-----+\n",
      "|   in24.inetnebr.com|01/Aug/1995:00:00...|   GET|/shuttle/missions...|HTTP/1.0|   200|        1839|    0|\n",
      "|     uplherc.upl.com|01/Aug/1995:00:00...|   GET|                   /|HTTP/1.0|   304|           0|    1|\n",
      "|     uplherc.upl.com|01/Aug/1995:00:00...|   GET|/images/ksclogo-m...|HTTP/1.0|   304|           0|    2|\n",
      "|     uplherc.upl.com|01/Aug/1995:00:00...|   GET|/images/MOSAIC-lo...|HTTP/1.0|   304|           0|    3|\n",
      "|     uplherc.upl.com|01/Aug/1995:00:00...|   GET|/images/USA-logos...|HTTP/1.0|   304|           0|    4|\n",
      "|ix-esc-ca2-07.ix....|01/Aug/1995:00:00...|   GET|/images/launch-lo...|HTTP/1.0|   200|        1713|    5|\n",
      "|     uplherc.upl.com|01/Aug/1995:00:00...|   GET|/images/WORLD-log...|HTTP/1.0|   304|           0|    6|\n",
      "|slppp6.intermind.net|01/Aug/1995:00:00...|   GET|/history/skylab/s...|HTTP/1.0|   200|        1687|    7|\n",
      "|piweba4y.prodigy.com|01/Aug/1995:00:00...|   GET|/images/launchmed...|HTTP/1.0|   200|       11853|    8|\n",
      "|slppp6.intermind.net|01/Aug/1995:00:00...|   GET|/history/skylab/s...|HTTP/1.0|   200|        9202|    9|\n",
      "|slppp6.intermind.net|01/Aug/1995:00:00...|   GET|/images/ksclogosm...|HTTP/1.0|   200|        3635|   10|\n",
      "|ix-esc-ca2-07.ix....|01/Aug/1995:00:00...|   GET|/history/apollo/i...|HTTP/1.0|   200|        1173|   11|\n",
      "|slppp6.intermind.net|01/Aug/1995:00:00...|   GET|/history/apollo/i...|HTTP/1.0|   200|        3047|   12|\n",
      "|     uplherc.upl.com|01/Aug/1995:00:00...|   GET|/images/NASA-logo...|HTTP/1.0|   304|           0|   13|\n",
      "|        133.43.96.45|01/Aug/1995:00:00...|   GET|/shuttle/missions...|HTTP/1.0|   200|       10566|   14|\n",
      "|kgtyk4.kj.yamagat...|01/Aug/1995:00:00...|   GET|                   /|HTTP/1.0|   200|        7280|   15|\n",
      "|kgtyk4.kj.yamagat...|01/Aug/1995:00:00...|   GET|/images/ksclogo-m...|HTTP/1.0|   200|        5866|   16|\n",
      "|     d0ucr6.fnal.gov|01/Aug/1995:00:00...|   GET|/history/apollo/a...|HTTP/1.0|   200|        2743|   17|\n",
      "|ix-esc-ca2-07.ix....|01/Aug/1995:00:00...|   GET|/shuttle/resource...|HTTP/1.0|   200|        6849|   18|\n",
      "|     d0ucr6.fnal.gov|01/Aug/1995:00:00...|   GET|/history/apollo/a...|HTTP/1.0|   200|       14897|   19|\n",
      "+--------------------+--------------------+------+--------------------+--------+------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Putting index column \n",
    "df_with_seq_id = logs_df.withColumn('index', row_number().over(Window.orderBy(monotonically_increasing_id())) - 1)\n",
    "df_with_seq_id.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14178"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows with potential null or missing values.\n",
    "bad_rows_df = df_with_seq_id.filter(logs_df['host'].isNull()|\n",
    "                             df_with_seq_id['timestamp'].isNull() |\n",
    "                             df_with_seq_id['method'].isNull() |\n",
    "                             df_with_seq_id['endpoint'].isNull() |\n",
    "                             df_with_seq_id['status'].isNull() |\n",
    "                             df_with_seq_id['content_size'].isNull()|\n",
    "                             df_with_seq_id['protocol'].isNull())\n",
    "bad_rows_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------+--------+--------+------+------------+-----+\n",
      "|host|timestamp|method|endpoint|protocol|status|content_size|index|\n",
      "+----+---------+------+--------+--------+------+------------+-----+\n",
      "|   0|        0|     0|       0|       0|     0|       14178|    0|\n",
      "+----+---------+------+--------+--------+------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find out which columns contains malformed entries.\n",
    "def count_null(col_name):\n",
    "    return spark_sum(col(col_name).isNull().cast('integer')).alias(col_name)\n",
    "\n",
    "# Build up a list of column expressions, one per column.\n",
    "exprs = [count_null(col_name) for col_name in df_with_seq_id.columns]\n",
    "\n",
    "# Run the aggregation. The *exprs converts the list of expressions into\n",
    "# variable function arguments.\n",
    "bad_rows_df.agg(*exprs).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling nulls in HTTP status\n",
    "regexp_extract('value', r'\\s(\\d{3})\\s', 1).cast('integer').alias( 'status')\n",
    "null_status_df = base_df.filter(~base_df['value'].rlike(r'\\s(\\d{3})\\s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass this through the log data parsing pipeline\n",
    "bad_status_df = null_status_df.select(regexp_extract('value', host_pattern, 1).alias('host'),\n",
    "                                      regexp_extract('value', ts_pattern, 1).alias('timestamp'),\n",
    "                                      regexp_extract('value', method_uri_protocol_pattern, 1).alias('method'),\n",
    "                                      regexp_extract('value', method_uri_protocol_pattern, 2).alias('endpoint'),\n",
    "                                      regexp_extract('value', method_uri_protocol_pattern, 3).alias('protocol'),\n",
    "                                      regexp_extract('value', status_pattern, 1).cast('integer').alias('status'),\n",
    "                                      regexp_extract('value', content_size_pattern, 1).cast('integer').alias('content_size'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------+--------+--------+------+------------+-----+\n",
      "|host|timestamp|method|endpoint|protocol|status|content_size|index|\n",
      "+----+---------+------+--------+--------+------+------------+-----+\n",
      "|   0|        0|     0|       0|       0|     0|       14178|    0|\n",
      "+----+---------+------+--------+--------+------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Handling nulls in HTTP content size\n",
    "logs_df = df_with_seq_id[logs_df['status'].isNotNull()]\n",
    "exprs = [count_null(col_name) for col_name in logs_df.columns]\n",
    "logs_df.agg(*exprs).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'CAST(regexp_extract(value, \\s(\\d+)$, 1) AS INT) AS `content_size`'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_extract('value', r'\\s(\\d+)$', 1).cast('integer').alias('content_size')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14178"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the records with potential missing content sizes in our base DataFrame\n",
    "null_content_size_df = base_df.filter(~base_df['value'].rlike(r'\\s\\d+$'))\n",
    "null_content_size_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------+--------+--------+------+------------+-----+\n",
      "|host|timestamp|method|endpoint|protocol|status|content_size|index|\n",
      "+----+---------+------+--------+--------+------+------------+-----+\n",
      "|   0|        0|     0|       0|       0|     0|           0|    0|\n",
      "+----+---------+------+--------+--------+------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fix the rows with null content_size -  replace the null values in logs_df with 0 \n",
    "logs_df = logs_df.na.fill({'content_size': 0})\n",
    "exprs = [count_null(col_name) for col_name in logs_df.columns]\n",
    "# the missing values in the content_size field with 0\n",
    "logs_df.agg(*exprs).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling temporal fields (timestamp) - parse the timestamp field into an actual timestamp.\n",
    "month_map = {\n",
    "  'Jan': 1, 'Feb': 2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7,\n",
    "  'Aug':8,  'Sep': 9, 'Oct':10, 'Nov': 11, 'Dec': 12\n",
    "}\n",
    "\n",
    "def parse_clf_time(text):\n",
    "    \"\"\" Convert Common Log time format into a Python datetime object\n",
    "    Args:\n",
    "        text (str): date and time in Apache time format [dd/mmm/yyyy:hh:mm:ss (+/-)zzzz]\n",
    "    Returns:\n",
    "        a string suitable for passing to CAST('timestamp')\n",
    "    \"\"\"\n",
    "    # NOTE: We're ignoring the time zones here, might need to be handled depending on the problem you are solving\n",
    "    return \"{0:04d}-{1:02d}-{2:02d} {3:02d}:{4:02d}:{5:02d}\".format(\n",
    "      int(text[7:11]),\n",
    "      month_map[text[3:6]],\n",
    "      int(text[0:2]),\n",
    "      int(text[12:14]),\n",
    "      int(text[15:17]),\n",
    "      int(text[18:20])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse our DataFrame's time column.\n",
    "udf_parse_time = udf(parse_clf_time)\n",
    "\n",
    "logs_df = (logs_df.select('*', udf_parse_time(logs_df['timestamp'])\n",
    "                                  .cast('timestamp')\n",
    "                                  .alias('time'))\n",
    "                  .drop('timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[host: string, method: string, endpoint: string, protocol: string, status: int, content_size: int, index: int, time: timestamp]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify by checking the DataFrame's schema.\n",
    "logs_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing SparkSession\n",
    "sc = SparkSession.builder.appName(\"PysparkExample\").config (\"spark.sql.shuffle.partitions\", \"50\").config(\"spark.driver.maxResultSize\",\"5g\").config (\"spark.sql.execution.arrow.enabled\", \"true\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registering a table\n",
    "logs_df.registerTempTable(\"data_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1: Top 10 requested pages and the number of requests made for each \n",
      "\n",
      "+--------------------+--------+\n",
      "|               pages|requests|\n",
      "+--------------------+--------+\n",
      "|/images/NASA-logo...|   96963|\n",
      "|/images/KSC-logos...|   75192|\n",
      "|/images/MOSAIC-lo...|   67062|\n",
      "|/images/USA-logos...|   66691|\n",
      "|/images/WORLD-log...|   66072|\n",
      "|/images/ksclogo-m...|   62405|\n",
      "|           /ksc.html|   43457|\n",
      "|/history/apollo/i...|   37772|\n",
      "|/images/launch-lo...|   35082|\n",
      "|                   /|   30097|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"q1: Top 10 requested pages and the number of requests made for each\",'\\n')\n",
    "\n",
    "sql = \"\"\"\n",
    "select endpoint as pages, count (endpoint) as requests\n",
    "from data_table \n",
    "where method = 'GET'\n",
    "group by endpoint\n",
    "order by requests desc\n",
    "limit 10\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q2: Percentage of successful requests (anything in the 200s and 300s range) \n",
      "\n",
      "+---------------------------------+\n",
      "|Percentage_of_successful_requests|\n",
      "+---------------------------------+\n",
      "|                99.34600846679211|\n",
      "+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"q2: Percentage of successful requests (anything in the 200s and 300s range)\",'\\n')\n",
    "\n",
    "sql = \"\"\"\n",
    "select (select count(status) from data_table where status like '2%%' or status like '3%%') / (select count(status) from data_table) * 100 as Percentage_of_successful_requests\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q3: Percentage of unsuccessful requests (anything that is not in the 200s or 300s range) \n",
      "\n",
      "+---------------------------------+\n",
      "|Percentage_of_successful_requests|\n",
      "+---------------------------------+\n",
      "|               0.6539915332078899|\n",
      "+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"q3: Percentage of unsuccessful requests (anything that is not in the 200s or 300s range)\",'\\n')\n",
    "\n",
    "sql = \"\"\"\n",
    "select (select count(status) from data_table where status NOT LIKE  '2%%' and status NOT LIKE '3%%') / (select count(status) from data_table) * 100 as Percentage_of_successful_requests\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q4: Top 10 unsuccessful page requests \n",
      "\n",
      "+--------------------+--------+\n",
      "|               pages|requests|\n",
      "+--------------------+--------+\n",
      "|/pub/winvn/readme...|    1337|\n",
      "|/pub/winvn/releas...|    1185|\n",
      "|/shuttle/missions...|     683|\n",
      "|/images/nasa-logo...|     319|\n",
      "|/shuttle/missions...|     253|\n",
      "|/elv/DELTA/uncons...|     209|\n",
      "|/history/apollo/s...|     200|\n",
      "|/://spacelink.msf...|     166|\n",
      "|/images/crawlerwa...|     160|\n",
      "|/history/apollo/a...|     154|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"q4: Top 10 unsuccessful page requests\",'\\n')\n",
    "\n",
    "sql = \"\"\"\n",
    "select endpoint as pages, count (endpoint) as requests\n",
    "from data_table \n",
    "where  status NOT LIKE  '2%%' \n",
    "and status NOT LIKE '3%%'\n",
    "and method = 'GET'\n",
    "group by endpoint\n",
    "order by requests desc\n",
    "limit 10\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q5: The top 10 hosts making the most requests, displaying the IP address and number of requests made. \n",
      "\n",
      "+--------------------+--------+\n",
      "|                host|requests|\n",
      "+--------------------+--------+\n",
      "|  edams.ksc.nasa.gov|    6528|\n",
      "|piweba4y.prodigy.com|    4846|\n",
      "|        163.206.89.4|    4791|\n",
      "|piweba5y.prodigy.com|    4607|\n",
      "|piweba3y.prodigy.com|    4416|\n",
      "|www-d1.proxy.aol.com|    3889|\n",
      "|www-b2.proxy.aol.com|    3534|\n",
      "|www-b3.proxy.aol.com|    3463|\n",
      "|www-c5.proxy.aol.com|    3423|\n",
      "|www-b5.proxy.aol.com|    3411|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"q5: The top 10 hosts making the most requests, displaying the IP address and number of requests made.\",'\\n')\n",
    "\n",
    "sql = \"\"\"\n",
    "select host, count (host) as requests\n",
    "from data_table \n",
    "where method = 'GET'\n",
    "group by host\n",
    "order by requests desc\n",
    "limit 10\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q7: For each of the top 10 hosts, show the top 5 pages requested and the number of requests for each page \n",
      "\n",
      "+--------------------+--------------------+---------------+\n",
      "|               hosts|               pages|requests_number|\n",
      "+--------------------+--------------------+---------------+\n",
      "|                    |     /whats-new.html|              4|\n",
      "|                    |    /test/index2.htm|              1|\n",
      "|         ***.novo.dk|/shuttle/missions...|              1|\n",
      "|         ***.novo.dk|/shuttle/countdow...|              1|\n",
      "|         ***.novo.dk|/shuttle/missions...|              1|\n",
      "|         ***.novo.dk|/shuttle/countdow...|              1|\n",
      "|         ***.novo.dk|/shuttle/missions...|              1|\n",
      "|001.msy4.communiq...|/images/WORLD-log...|              1|\n",
      "|001.msy4.communiq...|/software/winvn/w...|              1|\n",
      "|001.msy4.communiq...|/software/winvn/w...|              1|\n",
      "|001.msy4.communiq...|/software/winvn/w...|              1|\n",
      "|001.msy4.communiq...|/software/winvn/b...|              1|\n",
      "|      007.thegap.com|/images/NASA-logo...|              1|\n",
      "|      007.thegap.com|/shuttle/missions...|              1|\n",
      "|      007.thegap.com| /shuttle/countdown/|              1|\n",
      "|      007.thegap.com|/images/KSC-logos...|              1|\n",
      "|01-dynamic-c.woki...|/shuttle/countdow...|              1|\n",
      "|01-dynamic-c.woki...|/shuttle/countdow...|              1|\n",
      "|01-dynamic-c.woki...|/shuttle/countdow...|              1|\n",
      "|01-dynamic-c.woki...|/shuttle/countdow...|              1|\n",
      "+--------------------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"q7 (1st try): For each of the top 10 hosts, show the top 5 pages requested and the number of requests for each page\",'\\n')\n",
    "\n",
    "sql = \"\"\"\n",
    "select \n",
    "q.host as hosts,\n",
    "q.requested as pages,\n",
    "count(q.requested) as requests_number\n",
    "from \n",
    "(select \n",
    "T.host as host,\n",
    "T.endpoint as requested\n",
    "from (\n",
    "select T.host,T.endpoint,\n",
    "row_number() over(partition by T.host order by T.endpoint desc) as rn\n",
    "from data_table as T\n",
    "where method = 'GET'\n",
    ") as T\n",
    "where T.rn <= 5) as q\n",
    "group by q.host, q.requested\n",
    "order by hosts,requests_number desc\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q7: For each of the top 10 hosts, show the top 5 pages requested and the number of requests for each page \n",
      "\n",
      "+--------------------+--------------------+---+\n",
      "|                host|            endpoint| rn|\n",
      "+--------------------+--------------------+---+\n",
      "|                    |     /whats-new.html|  3|\n",
      "|                    |     /whats-new.html|  2|\n",
      "|                    |     /whats-new.html|  1|\n",
      "|                    |     /whats-new.html|  4|\n",
      "|                    |    /test/index2.htm|  5|\n",
      "|         ***.novo.dk|/shuttle/missions...|  1|\n",
      "|         ***.novo.dk|/shuttle/missions...|  2|\n",
      "|         ***.novo.dk|/shuttle/missions...|  3|\n",
      "|         ***.novo.dk|/shuttle/countdow...|  4|\n",
      "|         ***.novo.dk|/shuttle/countdow...|  5|\n",
      "|001.msy4.communiq...|/software/winvn/w...|  1|\n",
      "|001.msy4.communiq...|/software/winvn/w...|  2|\n",
      "|001.msy4.communiq...|/software/winvn/w...|  3|\n",
      "|001.msy4.communiq...|/software/winvn/b...|  4|\n",
      "|001.msy4.communiq...|/images/WORLD-log...|  5|\n",
      "|      007.thegap.com|/shuttle/missions...|  1|\n",
      "|      007.thegap.com| /shuttle/countdown/|  2|\n",
      "|      007.thegap.com|/images/NASA-logo...|  3|\n",
      "|      007.thegap.com|/images/KSC-logos...|  4|\n",
      "|01-dynamic-c.woki...|/shuttle/countdow...|  1|\n",
      "+--------------------+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"q7 (2nd try): For each of the top 10 hosts, show the top 5 pages requested and the number of requests for each page\",'\\n')\n",
    "\n",
    "sql = \"\"\"\n",
    "with rws as (\n",
    "  select o.host, o.endpoint, row_number () over (\n",
    "           partition by host\n",
    "           order by endpoint desc\n",
    "         ) rn\n",
    "  from   data_table as o\n",
    ")\n",
    "  select * from rws\n",
    "  where  rn <= 5\n",
    "  \n",
    "  order  by host, endpoint desc;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q7: For each of the top 10 hosts, show the top 5 pages requested and the number of requests for each page \n",
      "\n",
      "+-------------------+--------------------+--------------+\n",
      "|               host|                page|hosts_requests|\n",
      "+-------------------+--------------------+--------------+\n",
      "| edams.ksc.nasa.gov|           /ksc.html|          1020|\n",
      "| edams.ksc.nasa.gov|/images/WORLD-log...|           870|\n",
      "| edams.ksc.nasa.gov|/images/NASA-logo...|           869|\n",
      "| edams.ksc.nasa.gov|/images/MOSAIC-lo...|           867|\n",
      "| edams.ksc.nasa.gov|/images/USA-logos...|           867|\n",
      "| edams.ksc.nasa.gov|/images/ksclogo-m...|           866|\n",
      "|      inet2.tek.com|/shuttle/countdow...|           719|\n",
      "|zooropa.res.cmu.edu|                    |           624|\n",
      "|       163.206.89.4|/images/NASA-logo...|           568|\n",
      "|     beta.xerox.com|/images/NASA-logo...|           564|\n",
      "+-------------------+--------------------+--------------+\n",
      "\n",
      "+-------------------+--------------------+-------------+\n",
      "|               host|                page|page_requests|\n",
      "+-------------------+--------------------+-------------+\n",
      "| edams.ksc.nasa.gov|           /ksc.html|         1020|\n",
      "| edams.ksc.nasa.gov|/images/WORLD-log...|          870|\n",
      "| edams.ksc.nasa.gov|/images/NASA-logo...|          869|\n",
      "| edams.ksc.nasa.gov|/images/MOSAIC-lo...|          867|\n",
      "| edams.ksc.nasa.gov|/images/USA-logos...|          867|\n",
      "| edams.ksc.nasa.gov|/images/ksclogo-m...|          866|\n",
      "|      inet2.tek.com|/shuttle/countdow...|          719|\n",
      "|zooropa.res.cmu.edu|                    |          624|\n",
      "|       163.206.89.4|/images/NASA-logo...|          568|\n",
      "|     beta.xerox.com|/images/NASA-logo...|          564|\n",
      "+-------------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"q7 (compare): For each of the top 10 hosts, show the top 5 pages requested and the number of requests for each page\",'\\n')\n",
    "\n",
    "sql = \"\"\"\n",
    "select q.host, q.endpoint as page, count (q.host) as hosts_requests\n",
    "from data_table as q\n",
    "group by q.host, q.endpoint\n",
    "ORDER BY hosts_requests desc\n",
    "limit 10\n",
    "\"\"\"\n",
    "\n",
    "sql1 = \"\"\"\n",
    "select q.host,q.endpoint as page, count (q.endpoint) as page_requests\n",
    "from data_table as q\n",
    "group by  q.endpoint, q.host\n",
    "ORDER BY page_requests desc\n",
    "limit 10\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "spark.sql(sql).show()\n",
    "spark.sql(sql1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14178"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting malformed entries\n",
    "bad_rows_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+--------------------+--------+------+------------+-----+\n",
      "|                host|           timestamp|method|            endpoint|protocol|status|content_size|index|\n",
      "+--------------------+--------------------+------+--------------------+--------+------+------------+-----+\n",
      "|         gw1.att.com|01/Aug/1995:00:03...|   GET|/shuttle/missions...|HTTP/1.0|   302|        null|  158|\n",
      "|js002.cc.utsunomi...|01/Aug/1995:00:07...|   GET|/shuttle/resource...|HTTP/1.0|   404|        null|  321|\n",
      "|     tia1.eskimo.com|01/Aug/1995:00:28...|   GET|/pub/winvn/releas...|HTTP/1.0|   404|        null|  779|\n",
      "|itws.info.eng.nii...|01/Aug/1995:00:38...|   GET|/ksc.html/facts/a...|HTTP/1.0|   403|        null| 1066|\n",
      "|grimnet23.idirect...|01/Aug/1995:00:50...|   GET|/www/software/win...|HTTP/1.0|   404|        null| 1426|\n",
      "|miriworld.its.uni...|01/Aug/1995:01:04...|   GET|/history/history.htm|HTTP/1.0|   404|        null| 1730|\n",
      "|       ras38.srv.net|01/Aug/1995:01:05...|   GET|/elv/DELTA/uncons...|HTTP/1.0|   404|        null| 1735|\n",
      "|  cs1-06.leh.ptd.net|01/Aug/1995:01:17...|   GET|     /sts-71/launch/|        |   404|        null| 2021|\n",
      "|www-b2.proxy.aol.com|01/Aug/1995:01:22...|   GET|  /shuttle/countdown|HTTP/1.0|   302|        null| 2072|\n",
      "|     maui56.maui.net|01/Aug/1995:01:31...|   GET|            /shuttle|HTTP/1.0|   302|        null| 2303|\n",
      "+--------------------+--------------------+------+--------------------+--------+------+------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show all the malformed entries\n",
    "bad_rows_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registering a table with malformed entries\n",
    "bad_rows_df.registerTempTable(\"bad_rows_data_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"q8: The log file contains malformed entries; for each malformed line, display an error message and the line number.\") \n",
    "#sql = \"\"\"\n",
    "#SELECT *\n",
    "#FROM bad_rows_data_table \n",
    "#\"\"\"\n",
    "#spark.sql(sql).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q8: The log file contains malformed entries; for each malformed line, display an error message and the line number.,'\n",
      "'\n",
      "+------------------+-----+--------------------+--------------------+--------------------+--------+----+\n",
      "|     error_message|index|                host|           timestamp|            endpoint|protocol|size|\n",
      "+------------------+-----+--------------------+--------------------+--------------------+--------+----+\n",
      "|field size is null|  158|         gw1.att.com|01/Aug/1995:00:03...|/shuttle/missions...|HTTP/1.0|null|\n",
      "|field size is null|  321|js002.cc.utsunomi...|01/Aug/1995:00:07...|/shuttle/resource...|HTTP/1.0|null|\n",
      "|field size is null|  779|     tia1.eskimo.com|01/Aug/1995:00:28...|/pub/winvn/releas...|HTTP/1.0|null|\n",
      "|field size is null| 1066|itws.info.eng.nii...|01/Aug/1995:00:38...|/ksc.html/facts/a...|HTTP/1.0|null|\n",
      "|field size is null| 1426|grimnet23.idirect...|01/Aug/1995:00:50...|/www/software/win...|HTTP/1.0|null|\n",
      "|field size is null| 1730|miriworld.its.uni...|01/Aug/1995:01:04...|/history/history.htm|HTTP/1.0|null|\n",
      "|field size is null| 1735|       ras38.srv.net|01/Aug/1995:01:05...|/elv/DELTA/uncons...|HTTP/1.0|null|\n",
      "|field size is null| 2021|  cs1-06.leh.ptd.net|01/Aug/1995:01:17...|     /sts-71/launch/|        |null|\n",
      "|field size is null| 2072|www-b2.proxy.aol.com|01/Aug/1995:01:22...|  /shuttle/countdown|HTTP/1.0|null|\n",
      "|field size is null| 2303|     maui56.maui.net|01/Aug/1995:01:31...|            /shuttle|HTTP/1.0|null|\n",
      "+------------------+-----+--------------------+--------------------+--------------------+--------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"q8: The log file contains malformed entries; for each malformed line, display an error message and the line number.,'\\n'\") \n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT  case\n",
    "when content_size is null\n",
    "then 'field size is null'\n",
    "when host is null\n",
    "then 'field host is null'\n",
    "when host is null\n",
    "then 'field host is null'\n",
    "when timestamp is null\n",
    "then 'field timestamp is null'\n",
    "when endpoint is null\n",
    "then 'field endpoint is null'\n",
    "when protocol = ' '\n",
    "then 'field protocol is null'\n",
    "when method is null\n",
    "then 'field method is null'\n",
    "else 'No errors'\n",
    "end  as error_message , index, host, timestamp, endpoint, protocol, content_size as size\n",
    "FROM bad_rows_data_table \n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
